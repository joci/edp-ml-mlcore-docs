{"generatedAt":1678347460302,"generateTime":1185,"contents":[{"_path":"/docs/about","_dir":"docs","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"About","description":"","updated":"Last updateed May 4, 2022","author":"Written by EDP Team","Description":"Big Query ML Labs description","layout":"docs","body":{"type":"root","children":[{"type":"element","tag":"h3","props":{"id":"sub-title"},"children":[{"type":"text","value":"Sub title"}]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[{"id":"sub-title","depth":3,"text":"Sub title"}]}},"_type":"markdown","_id":"content:docs:about.md","_source":"content","_file":"docs/about.md","_extension":"md"},{"_path":"/docs/machine-learning-labs/big-query-ml-labs","_dir":"machine-learning-labs","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Big Query ML Labs","description":"","Description":"Big Query ML Labs description","layout":"docs","body":{"type":"root","children":[{"type":"element","tag":"h3","props":{"id":"build-and-deploy-a-model-with-workbench"},"children":[{"type":"text","value":"Build and deploy a model with Workbench"}]},{"type":"element","tag":"blockquote","props":{},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Why is Tailwind removing the default styles on my "},{"type":"element","tag":"code-inline","props":{},"children":[{"type":"text","value":"h1"}]},{"type":"text","value":" elements? How do I disable this? What do you mean I lose all the other base styles too?"}]}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Nuxt.js"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Nuxt Content module"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"TailwindCSS"},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"TailwindCSS typography"}]}]}]}]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[{"id":"build-and-deploy-a-model-with-workbench","depth":3,"text":"Build and deploy a model with Workbench"}]}},"_type":"markdown","_id":"content:docs:machine-learning-labs:big-query-ml-labs.md","_source":"content","_file":"docs/machine-learning-labs/big-query-ml-labs.md","_extension":"md"},{"_path":"/docs/machine-learning-labs","_dir":"docs","_draft":false,"_partial":false,"_locale":"","_empty":true,"title":"","description":"","navigation":false,"body":{"type":"root","children":[],"toc":{"title":"","searchDepth":5,"depth":5,"links":[]}},"_type":"markdown","_id":"content:docs:machine-learning-labs:index.md","_source":"content","_file":"docs/machine-learning-labs/index.md","_extension":"md"},{"_path":"/docs/machine-learning-labs/kubeflow-ml-labs","_dir":"machine-learning-labs","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Kubeflow ML Labs","description":"","Description":"Kubeflow ML Labs description","layout":"docs","tag":"kubeflow-ml-labs","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"kubeflow-ml-labs"},"children":[{"type":"text","value":"kubeflow-ml-labs"}]},{"type":"element","tag":"code","props":{"code":"/** @type {import('@tailwindlabs/lorem').ipsum} */\nexport default {\n  lorem: 'ipsum',\n  dolor: ['sit', 'amet', 'consectetur'],\n  adipiscing: {\n    elit: true,\n  },\n}\n","language":"js","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-36378d"},"children":[{"type":"text","value":"/** "}]},{"type":"element","tag":"span","props":{"class":"ct-9eb4b3"},"children":[{"type":"text","value":"@type"}]},{"type":"element","tag":"span","props":{"class":"ct-36378d"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-3f4801"},"children":[{"type":"text","value":"{import('@tailwindlabs/lorem').ipsum}"}]},{"type":"element","tag":"span","props":{"class":"ct-36378d"},"children":[{"type":"text","value":" */"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-2bf8bb"},"children":[{"type":"text","value":"export"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-2bf8bb"},"children":[{"type":"text","value":"default"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":" {"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-c0175a"},"children":[{"type":"text","value":"lorem:"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-fad553"},"children":[{"type":"text","value":"'ipsum'"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":","}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-c0175a"},"children":[{"type":"text","value":"dolor:"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":" ["}]},{"type":"element","tag":"span","props":{"class":"ct-fad553"},"children":[{"type":"text","value":"'sit'"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-fad553"},"children":[{"type":"text","value":"'amet'"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-fad553"},"children":[{"type":"text","value":"'consectetur'"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"],"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"  "}]},{"type":"element","tag":"span","props":{"class":"ct-c0175a"},"children":[{"type":"text","value":"adipiscing:"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":" {"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"    "}]},{"type":"element","tag":"span","props":{"class":"ct-c0175a"},"children":[{"type":"text","value":"elit:"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":" "}]},{"type":"element","tag":"span","props":{"class":"ct-9eb4b3"},"children":[{"type":"text","value":"true"}]},{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":","}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"  },"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cbc6cf"},"children":[{"type":"text","value":"}"}]}]}]}]}]},{"type":"element","tag":"style","children":[{"type":"text","value":".ct-fad553{color:#CE9178}\n.ct-c0175a{color:#9CDCFE}\n.ct-cbc6cf{color:#D4D4D4}\n.ct-2bf8bb{color:#C586C0}\n.ct-3f4801{color:#4EC9B0}\n.ct-9eb4b3{color:#569CD6}\n.ct-36378d{color:#6A9955}"}]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[]}},"_type":"markdown","_id":"content:docs:machine-learning-labs:kubeflow-ml-labs.md","_source":"content","_file":"docs/machine-learning-labs/kubeflow-ml-labs.md","_extension":"md"},{"_path":"/docs/machine-learning-labs/machine-learing-training","_dir":"machine-learning-labs","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Machine Learing Training","description":"Google Cloud's Vertex AI Workbench & Training - to build end-to-end ML workflows. You'll learn how to go from raw data to deployed model,and will leave this workshop ready to develop and productionize your own ML projects with Vertex AI.","updated":"Updateed May 4, 2022","author":"Written by EDP Team","tag":"machine-learing-training","layout":"lablist","body":{"type":"root","children":[{"type":"element","tag":"card-list","props":{},"children":[]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[]}},"_type":"markdown","_id":"content:docs:machine-learning-labs:Machine Learing Training.md","_source":"content","_file":"docs/machine-learning-labs/Machine Learing Training.md","_extension":"md"},{"_path":"/docs/machine-learning-labs/vertex-ai-pipeline-labs","_dir":"machine-learning-labs","_draft":false,"_partial":false,"_locale":"","_empty":true,"title":"vertex-ai-pipeline-labs","description":"Google Cloud's Vertex AI Workbench & Training - to build end-to-end ML workflows. You'll learn how to go from raw data to deployed model,and will leave this workshop ready to develop and productionize your own ML projects with Vertex AI.","updated":"Last updateed May 4, 2022","author":"Written by EDP Team","tag":"machine-learing-training","layout":"docs","body":{"type":"root","children":[],"toc":{"title":"","searchDepth":5,"depth":5,"links":[]}},"_type":"markdown","_id":"content:docs:machine-learning-labs:vertex-ai-pipeline-labs.md","_source":"content","_file":"docs/machine-learning-labs/vertex-ai-pipeline-labs.md","_extension":"md"},{"_path":"/docs/machine-learning-labs/workbench-ml-labs","_dir":"machine-learning-labs","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Build and deploy a model with Workbench","description":"Google Cloud's Vertex AI Workbench & Training - to build end-to-end ML workflows. You'll learn how to go from raw data to deployed model,and will leave this workshop ready to develop and productionize your own ML projects with Vertex AI.","updated":"Last updateed May 4, 2022","author":"Written by EDP Team","tag":"machine-learing-training","layout":"docs","body":{"type":"root","children":[{"type":"element","tag":"doc-card","props":{":summary":"true","title":"About this lab","updated":"May 4, 2022","writtenBy":"EDP Team"},"children":[]},{"type":"element","tag":"doc-card","props":{"id":"1"},"children":[{"type":"element","tag":"h3","props":{"id":"1-overview"},"children":[{"type":"element","tag":"span","props":{"class":"text-center text-gray-500 text-2xl mb-10 no-underline"},"children":[{"type":"text","value":"1. Overview"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this lab, you'll learn how to use Vertex AI - Google Cloud's newly announced managed ML platform - to build end-to-end ML workflows. You'll learn how to go from raw data to deployed model, and will leave this workshop ready to develop and productionize your own ML projects with Vertex AI.In this lab, we're using Cloud Shell to build a custom Docker image to demonstrate custom containers for training with Vertex AI."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"While we're using TensorFlow for the model code here, you could easily replace it with another framework."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"span","props":{"class":"text-sky-600"},"children":[{"type":"text","value":"Prerequisite"}]},{"type":"text","value":" :"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Basic knowledge of Machine Leaning"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"EDP Machine Learing Training Project (workbench enabled)"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"span","props":{"class":"text-sky-600"},"children":[{"type":"text","value":"Create New Workbench"}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"What you learn:"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Build and containerize model training code using Cloud Shell"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Submit a custom model training job to Vertex AI"}]},{"type":"element","tag":"li","props":{},"children":[]}]}]},{"type":"element","tag":"doc-card","props":{"id":"2"},"children":[{"type":"element","tag":"h3","props":{"id":"2-intro-to-vertex-ai"},"children":[{"type":"element","tag":"span","props":{"class":"text-center text-gray-500 text-2xl mb-10 no-underline"},"children":[{"type":"text","value":"2. Intro to Vertex AI"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This lab uses the newest AI product offering available on Google Cloud. Vertex AI integrates the ML offerings across Google Cloud into a seamless development experience. Previously, models trained with AutoML and custom models were accessible via separate services. The new offering combines both into a single API, along with other new products. You can also migrate existing projects to Vertex AI."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In addition to model training and deployment services, Vertex AI also includes a variety of MLOps products, including Vertex Pipelines (the focus of this lab), Model Monitoring, Feature Store, and more. You can see all Vertex AI product offerings in the diagram below."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"vertex-overview image","src":"/images/vertex-overview.png"},"children":[]}]}]},{"type":"element","tag":"doc-card","props":{"id":"3"},"children":[{"type":"element","tag":"h3","props":{"id":"3-cloud-environment-setup"},"children":[{"type":"element","tag":"span","props":{"class":"text-center text-gray-500 text-2xl mb-10 no-underline"},"children":[{"type":"text","value":"3. Cloud environment setup"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"You'll need a EDP Google Cloud ML Training Platform project. To create a project, follow the request form here."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 1: Start Cloud Shell"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"In this lab you're going to work in a Cloud Shell session, which is a command interpreter hosted by a virtual machine running in Google's cloud. You could just as easily run this section locally on your own computer, but using Cloud Shell gives everyone access to a reproducible experience in a consistent environment. After the lab, you're welcome to retry this section on your own computer."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Activate Cloud Shell"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"From the top right of the Cloud Console, click the button below to Activate Cloud Shell:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"activate image","src":"/images/activate.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"If you've never started Cloud Shell before, you're presented with an intermediate screen (below the fold) describing what it is. If that's the case, click Continue (and you won't ever see it again). Here's what that one-time screen looks like:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"cloud-shell-setup image","src":"/images/cloud-shell-setup.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"It should only take a few moments to provision and connect to Cloud Shell.\nThis virtual machine is loaded with all the development tools you need. It offers a persistent 5GB home directory and runs in Google Cloud, greatly enhancing network performance and authentication. Much, if not all, of your work in this codelab can be done with simply a browser or your Chromebook."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Once connected to Cloud Shell, you should see that you are already authenticated and that the project is already set to your project ID."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Run the following command in Cloud Shell to confirm that you are authenticated:"}]},{"type":"element","tag":"code","props":{"code":"gcloud auth login\ngcloud config set project <PROJECT_ID>\necho $GOOGLE_CLOUD_PROJECT\n","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"gcloud auth login\ngcloud config set project <PROJECT_ID>\necho $GOOGLE_CLOUD_PROJECT"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 2: Create a Cloud Storage Bucket"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"To run a training job on Vertex AI, we'll need a storage bucket to store our saved model assets. The bucket needs to be regional. We're using us-central here, but you are welcome to use another region (just replace it throughout this lab). If you already have a bucket you can skip this step."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Run the following commands in your Cloud Shell terminal to create a bucket:"}]},{"type":"element","tag":"code","props":{"code":"BUCKET_NAME=gs://$GOOGLE_CLOUD_PROJECT-mlcore/ml_models_bin\ngsutil mb -l us-central1 $BUCKET_NAME\n","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"BUCKET_NAME=gs://$GOOGLE_CLOUD_PROJECT-mlcore/ml_models_bin\ngsutil mb -l us-central1 $BUCKET_NAME"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 3: Create a Vertex AI Workbench instance"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"From the Vertex AI section of your Cloud Console, click on Workbench:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"select-workbench image","src":"/images/select-workbench.png","class":"w-52"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Please complete the following lab (skip this lab if you already have a workbench running): Create New Workbench"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 4: Open your Notebook"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Once the instance has been created, select Open JupyterLab:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"open-instance image","src":"/images/open-instance.png","class":"w-96"},"children":[]}]}]},{"type":"element","tag":"doc-card","props":{"id":"4"},"children":[{"type":"element","tag":"h3","props":{"id":"4-containerize-training-code"},"children":[{"type":"element","tag":"span","props":{"class":"text-center text-gray-500 text-2xl mb-10 no-underline"},"children":[{"type":"text","value":"4. Containerize training code"}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"We'll submit this training job to Vertex by putting our training code in a Docker container and pushing this container to Google Container Registry. Using this approach, we can train a model built with any framework."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 1: Set up files"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"To start, from the terminal in Workbench, run the following commands to create the files we'll need for our Docker Container:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"open-instance image","src":"/images/open-python-notebook.png","class":"w-80"},"children":[]}]},{"type":"element","tag":"code","props":{"code":"cd /home/jupyter/edp-ml-training/training\nmkdir mpg\ncd mpg\ntouch Dockerfile\nmkdir trainer\ntouch trainer/train.py\n","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"cd /home/jupyter/edp-ml-training/training\nmkdir mpg\ncd mpg\ntouch Dockerfile\nmkdir trainer\ntouch trainer/train.py"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"You should now have an mpg/ directory that looks like the following:"}]},{"type":"element","tag":"code","props":{"code":"+ Dockerfile\n+ trainer/\n    + train.py\n","language":"py","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"+ Dockerfile"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"+ trainer/"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"    + train.py"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"To view and edit these files, we'll use Workbench built-in code editor."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Open the Dockerfile and copy the following:"}]},{"type":"element","tag":"code","props":{"code":"FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\nWORKDIR /\n\n# Copies the trainer code to the docker image.\nCOPY trainer /trainer\n\n# Sets up the entry point to invoke the trainer.\nENTRYPOINT [\"python\", \"-m\", \"trainer.train\"]\n","language":"py","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-"}]},{"type":"element","tag":"span","props":{"class":"ct-eacb80"},"children":[{"type":"text","value":"3"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"WORKDIR /"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cac1c0"},"children":[{"type":"text","value":"# Copies the trainer code to the docker image."}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"COPY trainer /trainer"}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-cac1c0"},"children":[{"type":"text","value":"# Sets up the entry point to invoke the trainer."}]}]},{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"ENTRYPOINT ["}]},{"type":"element","tag":"span","props":{"class":"ct-751266"},"children":[{"type":"text","value":"\"python\""}]},{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-751266"},"children":[{"type":"text","value":"\"-m\""}]},{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":", "}]},{"type":"element","tag":"span","props":{"class":"ct-751266"},"children":[{"type":"text","value":"\"trainer.train\""}]},{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"]"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"wb-edit-docker image","src":"/images/wb-edit-docker.png"},"children":[]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This Dockerfile uses the Deep Learning Container TensorFlow Enterprise 2.3 Docker image. The Deep Learning Containers on Google Cloud come with many common ML and data science frameworks pre-installed. The one we're using includes TF Enterprise 2.3, Pandas, Scikit-learn, and others. After downloading that image, this Dockerfile sets up the entrypoint for our training code, which we'll add in the next step."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 2: Add model training code"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"From the Workbench editor, next open the train.py file and copy the code below (this is adapted from the tutorial in the TensorFlow docs)."}]},{"type":"element","tag":"code","props":{"code":"\n# This will be replaced with your bucket name after running the `sed` command in the tutorial\nBUCKET = \"BUCKET_NAME\"\n\nimport numpy as np\nimport pandas as pd\nimport pathlib\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n\n\"\"\"## The Auto MPG dataset\n\nThe dataset is available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n\n### Get the data\nFirst download the dataset.\n\"\"\"\n\n\"\"\"Import it using pandas\"\"\"\n\ndataset_path = \"https://storage.googleapis.com/io-vertex-codelab/auto-mpg.csv\"\ndataset = pd.read_csv(dataset_path, na_values = \"?\")\n\ndataset.tail()\n\n\"\"\"### Clean the data\n\nThe dataset contains a few unknown values.\n\"\"\"\n\ndataset.isna().sum()\n\n\"\"\"To keep this initial tutorial simple drop those rows.\"\"\"\n\ndataset = dataset.dropna()\n\n\"\"\"The `\"origin\"` column is really categorical, not numeric. So convert that to a one-hot:\"\"\"\n\ndataset['origin'] = dataset['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n\ndataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\ndataset.tail()\n\n\"\"\"### Split the data into train and test\n\nNow split the dataset into a training set and a test set.\n\nWe will use the test set in the final evaluation of our model.\n\"\"\"\n\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n\n\"\"\"### Inspect the data\n\nHave a quick look at the joint distribution of a few pairs of columns from the training set.\n\nAlso look at the overall statistics:\n\"\"\"\n\ntrain_stats = train_dataset.describe()\ntrain_stats.pop(\"mpg\")\ntrain_stats = train_stats.transpose()\ntrain_stats\n\n\"\"\"### Split features from labels\n\nSeparate the target value, or \"label\", from the features. This label is the value that you will train the model to predict.\n\"\"\"\n\ntrain_labels = train_dataset.pop('mpg')\ntest_labels = test_dataset.pop('mpg')\n\n\"\"\"\n### Normalize the data\n\nLook again at the `train_stats` block above and note how different the ranges of each feature are.\n\nIt is good practice to normalize features that use different scales and ranges. Although the model *might* converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input.\n\nNote: Although we intentionally generate these statistics from only the training dataset, these statistics will also be used to normalize the test dataset. We need to do that to project the test dataset into the same distribution that the model has been trained on.\n\"\"\"\n\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)\n\n\"\"\"This normalized data is what we will use to train the model.\n\nCaution: The statistics used to normalize the inputs here (mean and standard deviation) need to be applied to any other data that is fed to the model, along with the one-hot encoding that we did earlier.  That includes the test set as well as live data when the model is used in production.\n\n## The model\n\n### Build the model\n\nLet's build our model. Here, we'll use a `Sequential` model with two densely connected hidden layers, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model`, since we'll create a second model, later on.\n\"\"\"\n\ndef build_model():\n  model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\nmodel = build_model()\n\n\"\"\"### Inspect the model\n\nUse the `.summary` method to print a simple description of the model\n\"\"\"\n\nmodel.summary()\n\n\"\"\"Now try out the model. Take a batch of `10` examples from the training data and call `model.predict` on it.\n\nIt seems to be working, and it produces a result of the expected shape and type.\n\n### Train the model\n\nTrain the model for 1000 epochs, and record the training and validation accuracy in the `history` object.\n\nVisualize the model's training progress using the stats stored in the `history` object.\n\nThis graph shows little improvement, or even degradation in the validation error after about 100 epochs. Let's update the `model.fit` call to automatically stop training when the validation score doesn't improve. We'll use an *EarlyStopping callback* that tests a training condition for  every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training.\n\nYou can learn more about this callback [here](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping).\n\"\"\"\n\nmodel = build_model()\n\nEPOCHS = 1000\n\n# The patience parameter is the amount of epochs to check for improvement\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nearly_history = model.fit(normed_train_data, train_labels, \n                    epochs=EPOCHS, validation_split = 0.2, \n                    callbacks=[early_stop])\n\n\n# Export model and save to GCS\nmodel.save(BUCKET + '/mpg/model')\n\n","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{},"children":[{"type":"text","value":"\n# This will be replaced with your bucket name after running the `sed` command in the tutorial\nBUCKET = \"BUCKET_NAME\"\n\nimport numpy as np\nimport pandas as pd\nimport pathlib\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)\n\n\"\"\"## The Auto MPG dataset\n\nThe dataset is available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n\n### Get the data\nFirst download the dataset.\n\"\"\"\n\n\"\"\"Import it using pandas\"\"\"\n\ndataset_path = \"https://storage.googleapis.com/io-vertex-codelab/auto-mpg.csv\"\ndataset = pd.read_csv(dataset_path, na_values = \"?\")\n\ndataset.tail()\n\n\"\"\"### Clean the data\n\nThe dataset contains a few unknown values.\n\"\"\"\n\ndataset.isna().sum()\n\n\"\"\"To keep this initial tutorial simple drop those rows.\"\"\"\n\ndataset = dataset.dropna()\n\n\"\"\"The `\"origin\"` column is really categorical, not numeric. So convert that to a one-hot:\"\"\"\n\ndataset['origin'] = dataset['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n\ndataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\ndataset.tail()\n\n\"\"\"### Split the data into train and test\n\nNow split the dataset into a training set and a test set.\n\nWe will use the test set in the final evaluation of our model.\n\"\"\"\n\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n\n\"\"\"### Inspect the data\n\nHave a quick look at the joint distribution of a few pairs of columns from the training set.\n\nAlso look at the overall statistics:\n\"\"\"\n\ntrain_stats = train_dataset.describe()\ntrain_stats.pop(\"mpg\")\ntrain_stats = train_stats.transpose()\ntrain_stats\n\n\"\"\"### Split features from labels\n\nSeparate the target value, or \"label\", from the features. This label is the value that you will train the model to predict.\n\"\"\"\n\ntrain_labels = train_dataset.pop('mpg')\ntest_labels = test_dataset.pop('mpg')\n\n\"\"\"\n### Normalize the data\n\nLook again at the `train_stats` block above and note how different the ranges of each feature are.\n\nIt is good practice to normalize features that use different scales and ranges. Although the model *might* converge without feature normalization, it makes training more difficult, and it makes the resulting model dependent on the choice of units used in the input.\n\nNote: Although we intentionally generate these statistics from only the training dataset, these statistics will also be used to normalize the test dataset. We need to do that to project the test dataset into the same distribution that the model has been trained on.\n\"\"\"\n\ndef norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)\n\n\"\"\"This normalized data is what we will use to train the model.\n\nCaution: The statistics used to normalize the inputs here (mean and standard deviation) need to be applied to any other data that is fed to the model, along with the one-hot encoding that we did earlier.  That includes the test set as well as live data when the model is used in production.\n\n## The model\n\n### Build the model\n\nLet's build our model. Here, we'll use a `Sequential` model with two densely connected hidden layers, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model`, since we'll create a second model, later on.\n\"\"\"\n\ndef build_model():\n  model = keras.Sequential([\n    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\nmodel = build_model()\n\n\"\"\"### Inspect the model\n\nUse the `.summary` method to print a simple description of the model\n\"\"\"\n\nmodel.summary()\n\n\"\"\"Now try out the model. Take a batch of `10` examples from the training data and call `model.predict` on it.\n\nIt seems to be working, and it produces a result of the expected shape and type.\n\n### Train the model\n\nTrain the model for 1000 epochs, and record the training and validation accuracy in the `history` object.\n\nVisualize the model's training progress using the stats stored in the `history` object.\n\nThis graph shows little improvement, or even degradation in the validation error after about 100 epochs. Let's update the `model.fit` call to automatically stop training when the validation score doesn't improve. We'll use an *EarlyStopping callback* that tests a training condition for  every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training.\n\nYou can learn more about this callback [here](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping).\n\"\"\"\n\nmodel = build_model()\n\nEPOCHS = 1000\n\n# The patience parameter is the amount of epochs to check for improvement\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nearly_history = model.fit(normed_train_data, train_labels, \n                    epochs=EPOCHS, validation_split = 0.2, \n                    callbacks=[early_stop])\n\n\n# Export model and save to GCS\nmodel.save(BUCKET + '/mpg/model')"}]}]}]}]}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"Replace the following:"},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"text","value":"BUCKET_NAME: The Bucket created in \"Cloud environment setup\" section ("},{"type":"element","tag":"code-inline","props":{},"children":[{"type":"text","value":"<YOUR PROJECT NAME>-mlcore/ml_models_bin"}]},{"type":"text","value":")."}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Step 3: Build and test the container locally"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"From your Workbench Terminal, run the following to define a variable with the URI of your container image in Google Container Registry:"}]},{"type":"element","tag":"code","props":{"code":"IMAGE_URI=\"gcr.io/$GOOGLE_CLOUD_PROJECT/mpg:v1\"\n","language":"py","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"IMAGE_URI="}]},{"type":"element","tag":"span","props":{"class":"ct-751266"},"children":[{"type":"text","value":"\"gcr.io/$GOOGLE_CLOUD_PROJECT/mpg:v1\""}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Then, build the container by running the following from the root of your mpg directory:"}]},{"type":"element","tag":"code","props":{"code":"docker build ./ -t $IMAGE_URI\n","language":"py","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"docker build ./ -t "}]},{"type":"element","tag":"span","props":{"class":"ct-52062d"},"children":[{"type":"text","value":"$"}]},{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"IMAGE_URI"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Once you've built the container, push it to Google Container Registry:"}]},{"type":"element","tag":"code","props":{"code":"docker push $IMAGE_URI\n","language":"py","meta":null},"children":[{"type":"element","tag":"pre","props":{},"children":[{"type":"element","tag":"code","props":{"__ignoreMap":""},"children":[{"type":"element","tag":"div","props":{"class":"line"},"children":[{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"docker push "}]},{"type":"element","tag":"span","props":{"class":"ct-52062d"},"children":[{"type":"text","value":"$"}]},{"type":"element","tag":"span","props":{"class":"ct-470d1c"},"children":[{"type":"text","value":"IMAGE_URI"}]}]}]}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"To verify your image was pushed to Container Registry, you should see something like this when you navigate to the Container Registry section of your console:"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"img","props":{"alt":"wb-edit-docker image","src":"/images/container-reg.png","class":"w-96"},"children":[]}]}]},{"type":"element","tag":"doc-card","props":{"id":"5"},"children":[{"type":"element","tag":"h3","props":{"id":"5-run-a-training-job-on-vertex-ai"},"children":[{"type":"element","tag":"span","props":{"class":"text-center text-gray-500 text-2xl mb-10 no-underline"},"children":[{"type":"text","value":"5. Run a training job on Vertex AI"}]}]},{"type":"element","tag":"inline-alert","props":{},"children":[{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"You are welcome to experiment with larger machine types and GPUs if you'd like. If you use GPUs, you'll need to use a GPU-enabled base container image."}]}]}]},{"type":"element","tag":"style","children":[{"type":"text","value":".ct-52062d{color:#F44747}\n.ct-751266{color:#CE9178}\n.ct-cac1c0{color:#6A9955}\n.ct-eacb80{color:#B5CEA8}\n.ct-470d1c{color:#D4D4D4}"}]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[{"id":"1-overview","depth":3,"text":"1. Overview"},{"id":"2-intro-to-vertex-ai","depth":3,"text":"2. Intro to Vertex AI"},{"id":"3-cloud-environment-setup","depth":3,"text":"3. Cloud environment setup"},{"id":"4-containerize-training-code","depth":3,"text":"4. Containerize training code"},{"id":"5-run-a-training-job-on-vertex-ai","depth":3,"text":"5. Run a training job on Vertex AI"}]}},"_type":"markdown","_id":"content:docs:machine-learning-labs:workbench-ml-labs.md","_source":"content","_file":"docs/machine-learning-labs/workbench-ml-labs.md","_extension":"md"},{"_path":"/docs/machine-learning-training/training-services","_dir":"machine-learning-training","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Training Services","description":"","Description":"Big Query ML Labs description","layout":"docs","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"this-is-very-the-first-title-of-the-training-services-page"},"children":[{"type":"text","value":"This is very the First Title of the training services Page"}]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[]}},"_type":"markdown","_id":"content:docs:machine-learning-training:training-services.md","_source":"content","_file":"docs/machine-learning-training/training-services.md","_extension":"md"},{"_path":"/docs/machine-serving-training/batch-and-online","_dir":"machine-serving-training","_draft":false,"_partial":false,"_locale":"","_empty":false,"title":"Batch & Online","description":"","Description":"Batch & Online Labs description","layout":"docs","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"this-is-very-the-first-title-of-the-batch-online-services-page"},"children":[{"type":"text","value":"This is very the First Title of the Batch & Online services Page"}]}],"toc":{"title":"","searchDepth":5,"depth":5,"links":[]}},"_type":"markdown","_id":"content:docs:machine-serving-training:batch-&-online.md","_source":"content","_file":"docs/machine-serving-training/batch-&-online.md","_extension":"md"}],"navigation":[{"title":"Docs","_path":"/docs","children":[{"title":"About","_path":"/docs/about","layout":"docs"},{"title":"Machine Learning Labs","_path":"/docs/machine-learning-labs","children":[{"title":"Big Query ML Labs","_path":"/docs/machine-learning-labs/big-query-ml-labs","layout":"docs"},{"title":"Kubeflow ML Labs","_path":"/docs/machine-learning-labs/kubeflow-ml-labs","layout":"docs"},{"title":"Machine Learing Training","_path":"/docs/machine-learning-labs/machine-learing-training","layout":"lablist"},{"title":"vertex-ai-pipeline-labs","_path":"/docs/machine-learning-labs/vertex-ai-pipeline-labs","layout":"docs"},{"title":"Build and deploy a model with Workbench","_path":"/docs/machine-learning-labs/workbench-ml-labs","layout":"docs"}]},{"title":"Machine Learning Training","_path":"/docs/machine-learning-training","children":[{"title":"Training Services","_path":"/docs/machine-learning-training/training-services","layout":"docs"}]},{"title":"Machine Serving Training","_path":"/docs/machine-serving-training","children":[{"title":"Batch & Online","_path":"/docs/machine-serving-training/batch-and-online","layout":"docs"}]}]}]}